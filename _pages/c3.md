---
title: Wenbo Huang (黄文博) - C3"
layout: gridlay
excerpt: "Wenbo Huang: c3"
sitemap: false
permalink: /c3
---

[comment]: Title
<h2 align="center"> Shallow Convolutional Neural Networks for Human
Activity Recognition using Wearable Sensors </h2>
<p>&nbsp;</p>

[comment]: Authors
<p style="text-align: center;">
<a href="https://wenbohuang1002.github.io/" style="color: #CC0000">Wenbo Huang </a>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a style="color: #CC0000"> Lei Zhang* </a>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a style="color: #CC0000">Wenbin Gao</a>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</p>
<p>&nbsp;</p>

[comment]: Abstract
<h3> Abstract </h3>
<p style="text-align:justify; text-justify:inter-ideograph;">Due to rapid development of sensor technology, 
human activity recognition (HAR) using wearable inertial sensors
has recently become a new research hotspot. Deep learning, especially convolutional neural network (CNN) that can automatically
learn intricate activity features have gained a lot of attention in
ubiquitous HAR task. Most existing CNNs process sensor input
by extracting channel-wise features, and the information from
each channel can be separately propagated in a hierarchical way
from lower layers to higher layers. As a result, they typically
overlook information exchange among channels within the same
layer. In this paper, we first propose a shallow CNN that
considers cross-channel communication in HAR scenario, where
all channels in the same layer have a comprehensive interaction
to capture more discriminative features of sensor input. One
channel can communicate with all other channels by graph
neural network to remove redundant information accumulated
among channels, which is more beneficial for deploying light-weight deep models. Extensive experiments are conducted on
multiple benchmark HAR datasets, namely UCI-HAR, OPPORTUNITY, PAMAP2 and UniMib-SHAR, which indicates that the
proposed method enables shallower CNNs to aggregate more
useful information, and surpasses baseline deep networks and
other competitive methods. The inference speed is evaluated via
deploying the HAR systems on an embedded system.</p>

<center>
<figure>
		<div id="projectid">
    <img src="{{ site.url }}{{ site.baseurl }}/images/projectpic/21_TIM_C3.png" width="700px" />
		</div>

<figcaption>
<br>
Figure 1. The overview of C3 block

</figcaption>
</figure>
</center>


[comment]: Paper
<h3> Paper </h3>

- Paper: <a href="{{ site.url }}{{ site.baseurl }}/papers/TIM-2021-1.pdf" style="color: #CC0000"> Full-text link </a>

Please consider citing if this work and/or the corresponding code are useful for you:

```
@article{huang2021shallow,
  title={Shallow Convolutional Neural Networks for Human Activity Recognition Using Wearable Sensors},
  author={Huang, Wenbo and Zhang, Lei and Gao, Wenbin and Min, Fuhong and He, Jun},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--11},
  year={2021},
  publisher={IEEE}
}
```

[comment]: Code
<h3> Code </h3>
We use PyTorch to build network framework. Code is available online in ths github repository:
<a href="https://github.com/wenbohuang1002/Shallow-HAR" style="color: #CC0000">https://github.com/wenbohuang1002/Shallow-HAR</a>.
